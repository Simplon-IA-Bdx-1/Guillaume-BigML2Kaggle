<!----- Conversion time: 1.524 seconds.




Using this Markdown file:


1. Cut and paste this output into your source file.
2. See the notes and action items below regarding this conversion run.
3. Check the rendered output (headings, lists, code blocks, tables) for proper
   formatting and use a linkchecker before you publish this page.


Conversion notes:


* Docs to Markdown version 1.0β17
* Wed Nov 06 2019 04:43:26 GMT-0800 (PST)
* Source doc: https://docs.google.com/open?id=1GIj4tmC4qdgNi0tQd9-rkmoRHtGBUQWG6chOfFU8Loc
* This document has images: check for >>>>>  gd2md-html alert:  inline image link in generated source and store images to your server.
----->




<p style="color: red; font-weight: bold">>>>>>  gd2md-html alert:  ERRORs: 0; WARNINGs: 0; ALERTS: 5.</p>
<ul style="color: red; font-weight: bold"><li>See top comment block for details on ERRORs and WARNINGs. <li>In the converted Markdown or HTML, search for inline alerts that start with >>>>>  gd2md-html alert:  for specific instances that need correction.</ul>


<p style="color: red; font-weight: bold">Links to alert messages:</p><a href="#gdcalert1">alert1</a>
<a href="#gdcalert2">alert2</a>
<a href="#gdcalert3">alert3</a>
<a href="#gdcalert4">alert4</a>
<a href="#gdcalert5">alert5</a>


<p style="color: red; font-weight: bold">>>>>> PLEASE check and correct alert issues and delete this message and the inline alerts.<hr></p>




**Machine Learning Yearning-Draft - Andrew Ng**


**<span style="text-decoration:underline;">Résumé du chapitre 1er : Why Machine Learning Strategy</span>**


Le Machine Learning est la base dans différentes applications : reconnaissance vocale, …


<span style="text-decoration:underline;">Fil directeur du livre :</span> nous créons une startup spécialisée dans la reconnaissance d’images de chats. 


**<span style="text-decoration:underline;">Résumé chapitre 2eme : How to use this book to help your team</span>**


Pour la compréhension des définitions des paramètres techniques.


**<span style="text-decoration:underline;">Résumé chapitre 3eme : Prerequisites and Notation</span>**


Introduction au livre ...


**<span style="text-decoration:underline;">Résumé du Chapitre 4 : Scale drives machine learning progress</span>**


“People are now spending more time on digital devices . Their digital activities generate huge amounts of data that we can feed to our learning algorithms”


if you train larger and larger neural networks, you can obtain even better performance


But one of the more reliable ways to improve an algorithm’s performance today is still to train a bigger network and get more data. 






<p id="gdcalert1" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Resum-Alexis0.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert2">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>




![alt_text](images/Resum-Alexis0.png "image_tooltip")




<p id="gdcalert2" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Resum-Alexis1.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert3">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>




![alt_text](images/Resum-Alexis1.png "image_tooltip")




<p id="gdcalert3" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Resum-Alexis2.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert4">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>




![alt_text](images/Resum-Alexis2.png "image_tooltip")




*NN = Neural Network


**<span style="text-decoration:underline;">Résumé chapitre 5eme : Your development and test sets</span>**


Notre équipe récupère une large train set en téléchargeant des photos de chats et des photos sans chats sur différents sites. Malgré tout, la performance est insuffisante car décalage entre les photos uploadées par les utilisateurs (prises par téléphone, de moins bonne résolution ou floues) et celles récupérées sur internet pour entraîner notre training set.


On a pour habitude de définir :






*   Un training set : sur lequel on exerce notre algorithme d’apprentissage ;
*   Un “dev set” (validation) : utilisé pour sélectionner les features par exemple
*   Un test set : pour évaluer les performances de l’algorithme.


On doit choisir un dev et test set qui reflètent les données qu’on s’attend à collecter et sur lequel on souhaite réussir.


**<span style="text-decoration:underline;">Résumé chapitre 6eme : Your dev and test sets should come from the same distribution</span>**


L’auteur conseille fortement d’utiliser les dev et test sets d’une même distribution car :






*   S’ils proviennent d’une distribution différente, il est plus dur de trouver les erreurs (ou ce qui fonctionne)
*   Cela permet de prioriser les objectifs sur lesquels travailler.


**<span style="text-decoration:underline;">Résumé chapitre 7eme : How large do the dev/test sets need to be?</span>**


Le dev et le test set doivent être gros mais pas trop ni trop petit, suffisant pour pouvoir être évalués.


**<span style="text-decoration:underline;">Résumé chapitre 8eme : Establish a single-number evaluation metric for your team to optimize</span>**


Classification = métrique d’évaluation à un seul nombre, contrairement au Recall ou à la Précision. Du coup, si on a vraiment besoin du Recall et de la Précision, le mieux est de prendre la moyenne des 2 (pour avoir un seul nombre) ou en combinant leur moyenne. Avoir une métrique d’évaluation à un seul nombre permet de prendre une direction claire de progrès.


**<span style="text-decoration:underline;">Résumé chapitre 9eme : Optimizing and satisficing metrics</span>**


Autre moyen de combiner des métriques d’évaluation : comparer l’accuracy par rapport au temps de traitement : accuracy - (0.5*runningTime). Faut définir une limite à un temps de traitement acceptable et ensuite maximiser l’accuracy en respectant ces critères.


Egalement, il est intéressant de minimiser le taux des FN (faux négatifs).


**<span style="text-decoration:underline;">Résumé chapitre 10 : Having a dev set and metric speeds up iterations</span>**


Lors de la construction de la machine learning :






1. Commencer par une idée de comment construire le système
2. Implémenter l’idée dans le code
3. Expérimenter le code pour voir à quel point l'idée a fonctionné. (En général, les premières idées ne fonctionnent pas!) Sur la base de ces apprentissages, revenir en arrière pour générer plus d’idées et continuer d’itérer.


C'est un processus itératif. Plus vite on boucle, plus vite on progresse. C’est pourquoi il est important de disposer de dév / test sets.


Chaque fois qu’on essaie une idée, il faut mesurer les performances de l’idée sur le dév set, cela permet de décider rapidement si on se dirige dans la bonne direction.


**<span style="text-decoration:underline;">Résumé chapitre11 : When to change dev/test sets and metrics</span>**


Le dev et test set doivent être représentatif de ce que les utilisateurs feront. Il faut aussi regarder régulièrement les résultats et voir si on garde ou change le set actuel.


**<span style="text-decoration:underline;">Résumé chapitre 12 : Takeaways: Setting up development and test sets</span>**


Le chapitre est déjà un résumé de ce qui précède.


**<span style="text-decoration:underline;">Résumé chapitre 13 : Build your first system quickly, then iterate</span>**


Lorsque l’on s’attaque à un domaine d’application inconnu, rien ne sert de construire un système parfait. Mieux vaut construire et entraîner un système basique rapidement (en quelques jours). Cela nous montrera une direction prometteuse dans laquelle s’investir.


**<span style="text-decoration:underline;">Résumé chapitre 14 : Error analysis: Look at dev set examples to evaluate ideas</span>**


Le processus consistant à examiner des exemples mal classés est appelé <span style="text-decoration:underline;">analyse d'erreur</span> (​**error analysis​)**.


L'analyse d'erreur fait référence au processus consistant à examiner des exemples dev sets que l’algorithme a classés incorrectement, afin de comprendre les causes sous-jacentes des erreurs. Cela peut aider à hiérarchiser les projets.


**<span style="text-decoration:underline;">Résumé chapitre 15 : Evaluating multiple ideas in parallel during error analysis</span>**


Pour corriger les erreurs, on les répartit en sous catégorie par ordre d’importance. Il faudra ensuite travailler sur la résolution de ces erreurs par ordre de priorité.


**<span style="text-decoration:underline;">Résumé chapitre 16 : Cleaning up mislabeled dev and test set examples</span>**


Le but d’un dev set est de vous aider à rapidement évaluer si un algorithme est meilleur qu’un autre.


Si une partie du dataset est mal labellisé, cela peut impacter le jugement et il est judicieux de réparer ces erreurs.


**<span style="text-decoration:underline;">Résumé chapitre 17 : If you have a large dev set, split it into two subsets, only one of which you look at</span>**


Cela prends beaucoup de temps d’analyser un large set d’image, du coup il est plus judicieux de ne pas tous les utiliser dans une analyse d’erreur, vous pouvez utiliser une petite partie du set afin de corriger les erreurs du set.


**<span style="text-decoration:underline;">Résumé chapitre 18 : How big should the Eyeball and Blackbox dev sets be?</span>**


L’Eyeball dev set doit être suffisamment grand pour donner une idée des principales catégories d’erreurs de l’algorithme.


Si travailler sur une tâche que même les humains ne peuvent pas bien faire, alors l’exercice consistant à examiner un Eyeball dev ne sera pas aussi utile, car il est plus difficile de comprendre pourquoi l’algorithme n’a pas correctement classifié un exemple.


Dans ce cas, on peut ne pas avoir un Eyeball dev set.


Si on a un petit dev set, il se peut qu’on n’ait pas assez de données pour split l’Eyeball dev set et le Blackbox dev set.


Ainsi, on peut utiliser l'ensemble du dev set dans l’Eyeball dev set. L’Eyeball dev set est plus important que le Blackbox set.


**=> Si pas assez de données, tout mettre dans le Eyeball dev set.**


**<span style="text-decoration:underline;">Résumé chapitre 19 : Takeaways: Basic error analysis</span>**


Pour corriger les erreurs il faut regarder qu'est ce qui ne va pas.


**<span style="text-decoration:underline;">Résumé chapitre 20 : Bias and Variance: The two big sources of error</span>**


Il y a 2 sources principales d’erreurs : biais et variance.


Les performances entre les sous-ensemble de train et validation sont en général pire que celle entre le trainfull et le test.


**<span style="text-decoration:underline;">Résumé chapitre 21 : Examples of Bias and Variance</span>**


Overfitting = Le classificateur a très peu d'erreur d'apprentissage, mais il ne parvient pas à généraliser dans le dev set. ( % de bias bas mais % de variance haut).


Underfitting = Le classificateur adapte mal l’apprentissage (ex 15 % pour le bias), mais son erreur sur le dev set (ex dev error =16 %) est à peine supérieure à l’erreur du training set. ( % de bias haut mais % de variance bas). (ex variance ici 16 %-15 % = 1%)


Lorsque que le classificateur a un biais élevé et une variance élevée, il est à la fois overfitting et underfitting.


Lorsque que le classificateur possède un bias bas et une variance basse alors c’est une belle performance.


**<span style="text-decoration:underline;">Résumé chapitre 22 : Comparing to the optimal error rate</span>**


Rechercher le taux optimal d’erreur permet de mieux définir et évaluer notre modèle, en effet cela permet d’éviter certain biais ainsi que mieux planifier les étapes suivantes de création du modèle notamment sur les résultats obtenus.


**<span style="text-decoration:underline;">Résumé chapitre 23 : Addressing Bias and Variance</span>**


Afin de réduire les problèmes de biais et la variance il y a une formule simple pour y pallier : 






1. Si il y a des problèmes de biais augmentez la taille du modèle en ajoutant des couches de neurones par exemple 
2. Si il y a des problèmes de variance, ajoutez plus de données à votre jeu de donnée


Le fait d’ajouter des couches de neurones et ajouter des données peut pallier à la plupart des problèmes d’apprentissage du modèle.


**<span style="text-decoration:underline;">Résumé chapitre 24 : Bias vs. Variance tradeoff</span>**


Parmi tous les changements que l’on pourrait faire sur l’algorithme, il y a ceux qui réduisent les erreurs de biais mais au prix d'accroître la variance et vice versa. Cela créé un “échange” entre biais et variance.


Par exemple, augmenter la taille du modèle (en ajoutant des neurones ou couches dans un réseau de neurones ou en ajoutant des features à nos inputs) réduit en général le biais mais augmente la variance. A l’inverse, ajouter de la régularisation augmente généralement biais mais réduit la variance.


**<span style="text-decoration:underline;">Résumé chapitre 25 : Techniques for reducing avoidable bias</span>**






*   Augmenter la taille du modèle : cela va permettre de réduire le bias (et mieux entraîner le training set) mais si la variance augmente, il faut utiliser une régularisation.
*   Modifier les features en fonction des informations tirées de l'analyse d'erreur
*   Réduire ou enlever la régularisation (cela va permettre de réduire le bias mais cela augmente la variance)
*   Modifier l’architecture du modèle qui correspondrait mieux au problème (cela peut augmenter la variance et le bias)


Une autre technique qui n’affectera pas le bias : augmenter les données dans le training set (cela va permettre de réduire des problèmes liés la variance).


**<span style="text-decoration:underline;">Résumé chapitre 26 : Error analysis on the training set</span>**


Afin de corriger plus facilement les erreurs, il est possible de diviser les erreurs les plus importantes en sous ensemble d’erreur dans l’objectif de mieux les étudier. 


**<span style="text-decoration:underline;">Résumé chapitre 27 : Techniques for reducing variance</span>**


Si algorithme souffre d’une trop grosse variance vous devriez essayer les techniques suivante :






1. Ajouter plus de données d'entraînement
2. Ajouter “Regularisation”
3. Ajouter des “early stopping”
4. Sélectionner un certain nombre/type de features
5. Réduire la taille du modèle
6. Changer les Inputs en fonction des erreurs analysées 


**<span style="text-decoration:underline;">Résumé chapitre 28 : Diagnosing bias and variance: Learning curves</span>**


Vu que la taille du training set augmente, l’erreur du train set devrait décroître :


On va souvent avoir un “taux d’erreur désiré” dont on espère que notre algorithme d’apprentissage va atteindre. Par exemple :






*   Si on espère une performance au niveau humain, alors le taux d’erreur humaine peut être le “taux d’erreur désiré” ;
*   Si notre algorithme d’apprentissage doit être utilisé pour certains buts (comme délivrer des images de chats), on doit avoir une idée du niveau de performance qui est requis pour procurer une bonne expérience utilisateur.


**<span style="text-decoration:underline;">Résumé chapitre 29: Plotting training error</span>**


L’erreur sur le dev set diminue quand la taille du training set augmente.


L’erreur sur le training set augmente quand la taille du training set augmente.


Quand la taille du training set est petite, le modèle peut facilement mémoriser l’ensemble des information du training set.


Quand la taille du training set est très grande, il devient difficile de mémoriser parfaitement tous les exemples du training set.






<p id="gdcalert4" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Resum-Alexis3.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert5">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>




![alt_text](images/Resum-Alexis3.png "image_tooltip")




**<span style="text-decoration:underline;">Résumé chapitre : 30 Interpreting learning curves: High bias</span>**


Étudier les learning curves permet de mieux comprendre les biais du modèle. En effet  cela permet d’éviter de rajouter inutilement des datas supplémentaire dans le modèle dans le but d’augmenter la précision. Ceci étant dû au fait que dans certains cas le nombre d’erreur dans le training set augmente proportionnellement au fur et a mesure que l’on entraine le model.


**<span style="text-decoration:underline;">Résumé chapitre 31 : Interpreting learning curves: Other cases</span>**




<table>
  <tr>
   <td>


<p id="gdcalert5" ><span style="color: red; font-weight: bold">>>>>>  gd2md-html alert: inline image link here (to images/Resum-Alexis4.png). Store image on your image server and adjust path/filename if necessary. </span><br>(<a href="#">Back to top</a>)(<a href="#gdcalert6">Next alert</a>)<br><span style="color: red; font-weight: bold">>>>>> </span></p>




<img src="images/Resum-Alexis4.png" width="" alt="alt_text" title="image_tooltip">


<p>
Courbe Training error basse
<p>
Courbe Dev error est plus élevée que la Training error
<p>
Conclusion : le bias est petit mais la variance est élvée
<p>
Solution : augmenter le training data va aider à réduire le gap entre le dev error et le training error
   </td>
   <td>Courbe Training error haute (bien plus haute que le niveau désiré)
<p>
Courbe Dev error bien plus élevée que la courbe Training error
<p>
Conclusion : bias et variance sont élevés
<p>
Solution : Trouver un moyen de réduire le bias et la variance dans l’algorithme
   </td>
  </tr>
</table>




**<span style="text-decoration:underline;">Résumé chapitre 32 : Plotting learning curves</span>**


Si le bruit dans la courbe d’entraînement vous empêche de voir les vraies tendances, voici deux solutions:






*   Au lieu de former un seul modèle sur 10 exemples, choisissez plutôt plusieurs modèles (disons 3-10) différents ensembles d’entraînement choisis au hasard de 10 exemples par échantillonnage avec remplacement à partir de votre jeu initial de 100 valeurs. Entraînez un modèle différent sur chacun d’eux et calculez l’erreur sur le trainfull et sur le train de chacun des modèles résultants. Calculer et tracer l’erreur moyenne sur le trainfull et sur le train set.
*   Si votre jeu d’entraînement est orienté vers une classe ou s'il en a plusieurs, choisissez une option «Équilibré» au lieu de 10 exemples d’entraînement choisis au hasard parmi 100 éléments. Par exemple, vous pouvez vous assurer que 2/10 des exemples sont des exemples positifs et 8/10 des exemples négatifs. Plus généralement, assurez-vous que la fraction d’exemples de chaque classe est aussi réaliste que possible de l’ensemble global de valeurs.


**<span style="text-decoration:underline;">Résumé chapitre : 34 How to define human-level performance</span>**




<!-- Docs to Markdown version 1.0β17 -->